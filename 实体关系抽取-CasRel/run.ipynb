{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from model.casRel import CasRel\n",
    "from model.callback import MyCallBack\n",
    "from model.data import load_data, get_data_iterator\n",
    "from model.config import Config\n",
    "from model.evaluate import metric\n",
    "import torch.nn.functional as F\n",
    "from fastNLP import Trainer, LossBase\n",
    "\n",
    "seed = 226\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Model Controller')\n",
    "parser.add_argument('--lr', type=float, default=1e-5, help='learning rate')\n",
    "parser.add_argument('--batch_size', type=int, default=8)\n",
    "parser.add_argument('--max_epoch', type=int, default=10)\n",
    "parser.add_argument('--max_len', type=int, default=300)\n",
    "parser.add_argument('--dataset', default='finData', type=str, help='define your own dataset names')\n",
    "parser.add_argument(\"--bert_name\", default='./pretrained_models/bert-base-chinese/', type=str, help='choose pretrained bert name')\n",
    "parser.add_argument('--bert_dim', default=768, type=int)\n",
    "args = parser.parse_args(args=[])\n",
    "con = Config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(pred, gold, mask):\n",
    "    pred = pred.squeeze(-1)\n",
    "    loss = F.binary_cross_entropy(pred, gold, reduction='none')\n",
    "    if loss.shape != mask.shape:\n",
    "        mask = mask.unsqueeze(-1)\n",
    "    loss = torch.sum(loss * mask) / torch.sum(mask)\n",
    "    return loss\n",
    "\n",
    "def get_loss(predict, target):  # Casrel计算loss的方程\n",
    "    mask = target['mask']\n",
    "    return loss_fn(predict['sub_heads'], target['sub_heads'], mask) + \\\n",
    "            loss_fn(predict['sub_tails'], target['sub_tails'], mask) + \\\n",
    "            loss_fn(predict['obj_heads'], target['obj_heads'], mask) + \\\n",
    "            loss_fn(predict['obj_tails'], target['obj_tails'], mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pretrained_models/bert-base-chinese/ were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./pretrained_models/bert-base-chinese/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = CasRel(con).to(device)\n",
    "data_bundle, rel_vocab = load_data(con.train_path, con.dev_path, con.test_path, con.rel_path)\n",
    "train_dataset = get_data_iterator(con, data_bundle.get_dataset('train'), rel_vocab)\n",
    "dev_dataset = get_data_iterator(con, data_bundle.get_dataset('dev'), rel_vocab, is_test=True)\n",
    "test_dataset = get_data_iterator(con, data_bundle.get_dataset('test'), rel_vocab, is_test=True)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=con.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/776 [00:18<1:00:28,  4.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m epoch_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epoch_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(train_loader, model, optimizer, epoch)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# clear previous gradients, compute gradients of all variables wrt loss\u001b[39;00m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# gradient clipping\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# performs updates using calculated gradients\u001b[39;00m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# 要先Loss.backward()之后再用step,先清零参数空间的梯度,用了才会更新模型\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def train_epoch(train_loader, model, optimizer, epoch):\n",
    "    global train_data, batch_samples\n",
    "    # set model to training mode\n",
    "    model.train() # 不固定batch normalization和dropout，需要更新\n",
    "    # step number in one epoch: 336\n",
    "    train_losses = 0\n",
    "    for idx, batch_samples in enumerate(tqdm(train_loader)):  # tqdm是显示进度条的,每次加载一个batch32个数据\n",
    "        train_data = batch_samples[0]\n",
    "        target_data = batch_samples[1]\n",
    "        predict = model(train_data['token_ids'], train_data['mask'], \n",
    "                train_data['sub_head'], train_data['sub_tail'])\n",
    "        loss = get_loss(predict, target_data)\n",
    "        # compute model output and loss\n",
    "        train_losses += loss.item()\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()  # 要先Loss.backward()之后再用step,先清零参数空间的梯度,用了才会更新模型\n",
    "        #print(idx, train_losses)\n",
    "    train_loss = float(train_losses) / len(train_loader)\n",
    "    print(\"Epoch: {}, train loss: {}\".format(epoch, train_loss))\n",
    "    \n",
    "    #Dev\n",
    "    metric(dev_dataset, rel_vocab, con, model)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#best_val_f1 = 0.0\n",
    "#patience_counter = 0\n",
    "# start training\n",
    "epoch_num = 8\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    train_epoch(train_dataset, model, optimizer, epoch)\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save(model.state_dict(),'./net_epoch{}.pth'.format(epoch_num))\n",
    "    # val_metrics = evaluate(dev_loader, model, mode='dev')\n",
    "    # val_f1 = val_metrics['f1']\n",
    "    # val_p = val_metrics['p']\n",
    "    # val_r = val_metrics['r']\n",
    "#     logging.info(\"Epoch: {}, dev loss: {}, f1 score: {}, precision: {}, recall: {}\".format(epoch, val_metrics['loss'], val_f1, val_p, val_r))\n",
    "#     improve_f1 = val_f1 - best_val_f1\n",
    "#     if improve_f1 > 1e-5:\n",
    "#         best_val_f1 = val_f1\n",
    "#         model.save_pretrained(model_dir)\n",
    "#         logging.info(\"--------Save best model!--------\")\n",
    "#         if improve_f1 < config.patience:\n",
    "#             patience_counter += 1\n",
    "#         else:\n",
    "#             patience_counter = 0\n",
    "#     else:\n",
    "#         patience_counter += 1\n",
    "#     # Early stopping and logging best f1\n",
    "#     if (patience_counter >= config.patience_num and epoch > config.min_epoch_num) or epoch == config.epoch_num:\n",
    "#         logging.info(\"Best val f1: {}\".format(best_val_f1))\n",
    "#         break\n",
    "# logging.info(\"Training Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:02<00:00, 13.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_num:   0, predict_num:   0, gold_num:  63\n",
      "f1: 0.00, precision: 0.00, recall: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00, 11.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "orders = ['subject', 'relation', 'object']\n",
    "correct_num, predict_num, gold_num = 0, 0, 0\n",
    "tokenizer = BertTokenizer.from_pretrained(con.bert_name)\n",
    "\n",
    "for batch_x, batch_y in tqdm(dev_dataset):  # x用来测试，y是准确的数据集\n",
    "    with torch.no_grad():\n",
    "        token_ids = batch_x['token_ids']\n",
    "        mask = batch_x['mask']\n",
    "        encoded_text = model.get_encoded_text(token_ids, mask)\n",
    "        pred_sub_heads, pred_sub_tails = model.get_subs(encoded_text)  # 预测\n",
    "        sub_heads = torch.where(pred_sub_heads[0] > 0.05)[0]\n",
    "        # if len(sub_heads)>0:\n",
    "        #     print(sub_heads)\n",
    "        sub_tails = torch.where(pred_sub_tails[0] > 0.5)[0]\n",
    "        subjects = []\n",
    "        for sub_head in sub_heads:\n",
    "            sub_tail = sub_tails[sub_tails >= sub_head]\n",
    "            if len(sub_tail) > 0:\n",
    "                sub_tail = sub_tail[0]\n",
    "                subject = ''.join(tokenizer.decode(token_ids[0][sub_head: sub_tail + 1]).split())\n",
    "                subjects.append((subject, sub_head, sub_tail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./pretrained_models/bert-base-chinese/ were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./pretrained_models/bert-base-chinese/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from collections import defaultdict\n",
    "def find_head_idx(source, target):\n",
    "    target_len = len(target)\n",
    "    for i in range(len(source)):\n",
    "        if source[i: i + target_len] == target:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(con.bert_name)\n",
    "bert = BertModel.from_pretrained(con.bert_name)\n",
    "\n",
    "json_data = data_bundle.get_dataset('train')[223]\n",
    "tokenized = tokenizer(json_data['text'])\n",
    "tokens = tokenized['input_ids'] # 句子的length\n",
    "masks = tokenized['attention_mask']\n",
    "text_len = len(tokens)\n",
    "\n",
    "token_ids = torch.tensor(tokens, dtype=torch.long)\n",
    "masks = torch.tensor(masks, dtype=torch.bool)\n",
    "\"\"\"主体和客体起始位置的记录\"\"\"\n",
    "sub_heads, sub_tails = torch.zeros(text_len), torch.zeros(text_len)\n",
    "sub_head, sub_tail = torch.zeros(text_len), torch.zeros(text_len)\n",
    "obj_heads = torch.zeros((text_len, con.num_relations))\n",
    "obj_tails = torch.zeros((text_len, con.num_relations))\n",
    "\n",
    "s2ro_map = defaultdict(list)  # 创建一个dictionary，将键-值对更新为键-列表对，每个键可以调用list的属性\n",
    "for spo in json_data['spo_list']:\n",
    "    triple = (tokenizer(spo['subject'], add_special_tokens=False)['input_ids'], \n",
    "                rel_vocab.to_index(spo['predicate']),\n",
    "                tokenizer(spo['object'], add_special_tokens=False)['input_ids']) # 把文本转换成id然后记录三元组,同时避免加入[CLS][SEP]这些特殊符号\n",
    "    \"\"\"\n",
    "    - ISSUE: 如果某一个词语多次出现则只能找到第一个位置，这里有问题\n",
    "    - SOLUTION: 再加一个变量记录这个词语是否出现过，如果出现过就记录他的位置，然后从这个位置开始往后找\n",
    "    - WHY: 其实不改也可以，因为一个主体在文本中的意思应该是一样的。但是因为BERT模型会考虑前后文信息所以最好还是改一下？不确定，看验证结果，不是很严重的问题。\n",
    "    \"\"\"\n",
    "    sub_head_idx = find_head_idx(tokens, triple[0])\n",
    "    obj_head_idx = find_head_idx(tokens, triple[2])\n",
    "    \"\"\"可以试一下assert判断+终止\"\"\"\n",
    "    if sub_head_idx != -1 and obj_head_idx != -1:\n",
    "        sub = (sub_head_idx, sub_head_idx + len(triple[0]) - 1) # 主体位置\n",
    "        s2ro_map[sub].append(\n",
    "            (obj_head_idx, obj_head_idx + len(triple[2]) - 1, triple[1]))  # 用append解决一个主体对应多个客体的问题。客体位置+关系\n",
    "\n",
    "if s2ro_map:  # 可能没有记录\n",
    "    for s in s2ro_map:\n",
    "        sub_heads[s[0]] = 1\n",
    "        sub_tails[s[1]] = 1\n",
    "    sub_head_idx, sub_tail_idx = choice(list(s2ro_map.keys()))\n",
    "    sub_head[sub_head_idx] = 1\n",
    "    sub_tail[sub_tail_idx] = 1\n",
    "    for ro in s2ro_map.get((sub_head_idx, sub_tail_idx), []):\n",
    "        obj_heads[ro[0]][ro[2]] = 1\n",
    "        obj_tails[ro[1]][ro[2]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "relation = []\n",
    "event = []\n",
    "with open('./data/data2.0.json', 'r', encoding='utf-8') as json_file:\n",
    "    f = json_file.readlines()\n",
    "    for line in f:\n",
    "        json_line = json.loads(line.strip())\n",
    "        relation += json_line['result']['data']['normal']\n",
    "        event += json_line['result']['data']['cangu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relation)\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_relations(relations):\n",
    "    ret = []\n",
    "    for item in relations:\n",
    "        results = item['results']\n",
    "        if results:\n",
    "            add = True\n",
    "            for rel in results:\n",
    "                if rel['head'] == '公司' or rel['head'] == '本公司':\n",
    "                    if random.random() > 0.2:\n",
    "                        add = False\n",
    "                        break\n",
    "            if add:\n",
    "                ret.append(item)\n",
    "    return ret\n",
    "a = clean_relations(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '交易完成后，公司占华高世纪股权比例为99.56%，华高世纪成为公司控股子公司。',\n",
       "  'results': [{'head': '公司', 'relation': '子公司', 'tail': '华高世纪'}]},\n",
       " {'text': '基于神州高铁整线智能运营优势以及在天津市轨道交通的深耕布局,经与中国交建等方面洽商一致,2020年7月15日神州高铁及子公司神州高铁轨道交通运营管理有限公司(以下简称“神铁运营”,神州高铁与神铁运营合称“神州高铁方”)与中国交建签署了《天津地铁2、3号线存量PPP项目股权转让框架协议》,中国交建同意按照天津市政府转让的相关条件,将其持有的2号线和3号线项目公司部分股权转让给神州高铁方,神州高铁方同意按照相关条件受让前述股权。',\n",
       "  'results': [{'head': '神州高铁',\n",
       "    'relation': '子公司',\n",
       "    'tail': '神州高铁轨道交通运营管理有限公司'}]},\n",
       " {'text': '为解决宝安鸿基地产集团股份有限公司（以下简称“宝安地产”）与本公司在惠州地区存在的同业竞争，宝安地产拟以人民币17,000万元受让本公司之全资子公司惠州市宝安房地产开发有限公司（以下简称“惠州地产公司”）100%股权。',\n",
       "  'results': [{'head': '本公司', 'relation': '子公司', 'tail': '惠州市宝安房地产开发有限公司'},\n",
       "   {'head': '本公司', 'relation': '子公司', 'tail': '惠州市宝安房地产开发有限公司'}]},\n",
       " {'text': '中国宝安集团股份有限公司（以下简称“公司”）控股子公司深圳市贝特瑞新能源材料股份有限公司（证券简称：贝特瑞，证券代码：835185）于2018年10月26日召开了第四届董事会第三十三次会议，审议通过了《关于转让广东芳源环保股份有限公司部分股权的议案》，同意贝特瑞在未来12个月内通过全国中小企业股份转让系统转让所持有的广东芳源环保股份有限公司（证券简称：芳源环保，证券代码：839247）股份不超过1,000万股，详见贝特瑞在全国中小企业股份转让系统发布的《第四届董事会第三十三次会议决议公告》（公告编号：2018-089）。',\n",
       "  'results': [{'head': '中国宝安集团股份有限公司',\n",
       "    'relation': '子公司',\n",
       "    'tail': '深圳市贝特瑞新能源材料股份有限公司'}]},\n",
       " {'text': '一、交易概况中国宝安集团股份有限公司（以下简称“公司”）控股子公司贝特瑞新材料集团股份有限公司（证券简称：贝特瑞，证券代码：835185）拟通过协议转让的方式，以12-13元/股的价格向公司非关联方转让其所持有的广东芳源环保股份有限公司（以下简称“芳源环保”）股份不超过700万股，最终转让价格和转让数量在上述范围内由交易双方协商确定。',\n",
       "  'results': [{'head': '中国宝安集团股份有限公司',\n",
       "    'relation': '子公司',\n",
       "    'tail': '贝特瑞新材料集团股份有限公司'}]},\n",
       " {'text': '中国宝安集团股份有限公司(以下简称“公司”)控股子公司贝特瑞新材料集团股份有限公司(证券简称“贝特瑞”,证券代码:835185)为了集中资源聚焦核心业务,增强其核心竞争力,于2020年12月25日与江苏龙蟠科技股份有限公司(证券简称“龙蟠科技”,证券代码:603906)在深圳签署了《关于收购贝特瑞新材料集团股份有限公司名下磷酸铁锂相关资产和业务之框架协议》(以下简称“《框架协议》”“本框架协议”),龙蟠科技拟收购贝特瑞合并报表范围内的磷酸铁锂相关资产和业务(以下简称“标的资产和业务”),贝特瑞同意龙蟠科技收购上述标的资产和业务。',\n",
       "  'results': [{'head': '中国宝安集团股份有限公司',\n",
       "    'relation': '子公司',\n",
       "    'tail': '贝特瑞新材料集团股份有限公司'}]},\n",
       " {'text': '本次龙蟠科技拟收购贝特瑞合并报表范围内的磷酸铁锂相关资产和业务事项(以下简称“本次交易事项”)不构成关联交易,也不构成《上市公司重大资产重组管理办法》规定的重大资产重组。',\n",
       "  'results': [{'head': '龙蟠科技', 'relation': '业务', 'tail': '磷酸铁锂'}]},\n",
       " {'text': '南玻集团控股子公司--深圳南玻伟光导电膜有限公司（以下简称“伟光导电膜”）出于业务发展的需要，向深圳顺络电子股份有限公司（以下简称“顺络电子”）收购深圳顺络科技有限公司（以下简称“顺络科技”）100%股权。',\n",
       "  'results': [{'head': '南玻集团', 'relation': '子公司', 'tail': '深圳南玻伟光导电膜有限公司'}]},\n",
       " {'text': '为优化公司资产配置,推动下属公司资本化运作,康佳集团股份有限公司(以下简称“本公司”)正在筹划在国有产权交易所公开挂牌转让控股子公司毅康科技有限公司(以下简称“毅康公司”)不超过15%股权。',\n",
       "  'results': [{'head': '康佳集团股份有限公司', 'relation': '子公司', 'tail': '毅康科技有限公司'}]},\n",
       " {'text': '毅康公司为本公司持股51%的控股子公司,主要从事综合水务治理业务。',\n",
       "  'results': [{'head': '毅康公司', 'relation': '业务', 'tail': '综合水务治理'}]}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9864"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '2009年6月12日,信息披露义务人与中国平安签署了《股份购买协议》,协议主要内容如下:转让方将向受让方转让其持有的深发展520,414,439股股份,占深发展总股本的16.76%。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '转让事件',\n",
       "    'arguments': [{'argument': '深发展',\n",
       "      'role': '被转让方|公司',\n",
       "      'argument_start_index': 58}]},\n",
       "   {'trigger': '持有',\n",
       "    'event_type': '参股事件',\n",
       "    'arguments': [{'argument': '深发展',\n",
       "      'role': '被参股方|公司',\n",
       "      'argument_start_index': 58},\n",
       "     {'argument': '16.76%', 'role': '参股比例|数值', 'argument_start_index': 84}]}]},\n",
       " {'text': '深圳发展银行股份有限公司拟向中国平安保险（集团）股份有限公司（“中国平安”）发行股份（“本次发行”），中国平安拟以其持有的平安银行股份有限公司（“平安银行”）约90.75%的股份以及部分现金认购公司本次发行的股份。',\n",
       "  'pre_events': [{'trigger': '持有',\n",
       "    'event_type': '参股事件',\n",
       "    'arguments': [{'argument': '中国平安',\n",
       "      'role': '参股方|公司',\n",
       "      'argument_start_index': 51},\n",
       "     {'argument': '平安银行股份有限公司', 'role': '被参股方|公司', 'argument_start_index': 61},\n",
       "     {'argument': '90.75%', 'role': '参股比例|数值', 'argument_start_index': 80}]}]},\n",
       " {'text': '公司之全资子公司万科置业（香港）有限公司（简称“万科置业”）于2012年5月13日与永泰地产有限公司（简称“永泰地产”，香港联合交易所股份代码0369）达成协议，在南联地产控股有限公司（简称“南联地产”，香港联合交易所股份代码1036）进行公司重组后，万科置业将通过其全资子公司WklandInvestmentsCompanyLimited以约港币10.79亿元向永泰地产收购重组后的南联地产191,935,845股股份，占重组后的南联地产已发行股份总数的约73.91%。',\n",
       "  'pre_events': [{'trigger': '收购',\n",
       "    'event_type': '参股事件',\n",
       "    'arguments': [{'argument': '万科置业',\n",
       "      'role': '参股方|公司',\n",
       "      'argument_start_index': 126},\n",
       "     {'argument': 'WklandInvestmentsCompanyLimited',\n",
       "      'role': '参股方|公司',\n",
       "      'argument_start_index': 139},\n",
       "     {'argument': '永泰地产', 'role': '被参股方|公司', 'argument_start_index': 182},\n",
       "     {'argument': '南联地产', 'role': '参股方|公司', 'argument_start_index': 192}]}]},\n",
       " {'text': '2012-07-18：1港币=0.8218人民币元2012年7月16日，南联地产完成公司重组；前述股份收购已经完成，WklandInvestmentsCompanyLimited已经持有重组后的南联地产205,835,845股股份，占重组后的南联地产已发行股份总数的约79.26%。',\n",
       "  'pre_events': [{'trigger': '持有',\n",
       "    'event_type': '参股事件',\n",
       "    'arguments': [{'argument': 'WklandInvestmentsCompanyLimited',\n",
       "      'role': '参股方|公司',\n",
       "      'argument_start_index': 58},\n",
       "     {'argument': '南联地产', 'role': '被参股方|公司', 'argument_start_index': 97},\n",
       "     {'argument': '79.26%',\n",
       "      'role': '参股比例|数值',\n",
       "      'argument_start_index': 134}]}]},\n",
       " {'text': '概述：经本公司与武汉中百集团股份有限公司协商，同意本公司控股企业--深圳市金田商业网络发展有限公司与深圳市金田投资有限公司将所持有的武汉金田连锁商场有限责任公司、武汉金田超市有限责任公司的股权全部转让给武汉中百集团股份有限公司、武汉中百仓储连锁超市有限公司，转让金额合计430万元。',\n",
       "  'pre_events': [{'trigger': '控股',\n",
       "    'event_type': '参股事件',\n",
       "    'arguments': [{'argument': '本公司',\n",
       "      'role': '参股方|公司',\n",
       "      'argument_start_index': 25},\n",
       "     {'argument': '深圳市金田商业网络发展有限公司',\n",
       "      'role': '被参股方|公司',\n",
       "      'argument_start_index': 34},\n",
       "     {'argument': '武汉金田连锁商场有限责任公司',\n",
       "      'role': '被参股方|公司',\n",
       "      'argument_start_index': 66}]},\n",
       "   {'trigger': '持有',\n",
       "    'event_type': '参股事件',\n",
       "    'arguments': [{'argument': '深圳市金田商业网络发展有限公司',\n",
       "      'role': '参股方|公司',\n",
       "      'argument_start_index': 34},\n",
       "     {'argument': '深圳市金田投资有限公司', 'role': '参股方|公司', 'argument_start_index': 50},\n",
       "     {'argument': '武汉金田连锁商场有限责任公司',\n",
       "      'role': '被参股方|公司',\n",
       "      'argument_start_index': 66},\n",
       "     {'argument': '武汉金田超市有限责任公司',\n",
       "      'role': '被参股方|公司',\n",
       "      'argument_start_index': 81}]},\n",
       "   {'trigger': '转让',\n",
       "    'event_type': '转让事件',\n",
       "    'arguments': [{'argument': '深圳市金田商业网络发展有限公司',\n",
       "      'role': '转让方|公司',\n",
       "      'argument_start_index': 34},\n",
       "     {'argument': '深圳市金田投资有限公司', 'role': '转让方|公司', 'argument_start_index': 50},\n",
       "     {'argument': '武汉金田连锁商场有限责任公司',\n",
       "      'role': '被转让方|公司',\n",
       "      'argument_start_index': 66},\n",
       "     {'argument': '武汉金田超市有限责任公司',\n",
       "      'role': '被转让方|公司',\n",
       "      'argument_start_index': 81},\n",
       "     {'argument': '武汉中百集团股份有限公司',\n",
       "      'role': '接收方|公司',\n",
       "      'argument_start_index': 101},\n",
       "     {'argument': '武汉中百仓储连锁超市有限公司',\n",
       "      'role': '接收方|公司',\n",
       "      'argument_start_index': 114}]}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parse_events(events):\n",
    "    ret = []\n",
    "    tri_dic = {}\n",
    "    for item in events:\n",
    "        es = item['pre_events']\n",
    "        for e in es:\n",
    "            tri_dic[e['trigger']] = tri_dic[e['trigger']] + 1 if e['trigger'] in tri_dic else 1\n",
    "            #if e['event_type'] == '转让事件':\n",
    "       \n",
    "    white_triggers = [key  for key in tri_dic if tri_dic[key] >= 5]\n",
    "\n",
    "    for item in events:\n",
    "        es = item['pre_events']\n",
    "        add = True\n",
    "        for e in es:\n",
    "            if e['trigger'] not in white_triggers or len(e['arguments']) < 2 or e['event_type'] != '购买事件':\n",
    "                add = False\n",
    "                break\n",
    "        if add:\n",
    "            ret.append(item)\n",
    "            '''\n",
    "            tmp = {}\n",
    "            tmp['text'] = item['text']\n",
    "            tmp['results'] = []\n",
    "            for e in es:\n",
    "                sop = {}\n",
    "                sop['relation'] = '参股'\n",
    "                for arg in e['arguments']:\n",
    "                    if arg['role'] == '参股方|公司':\n",
    "                        sop['head'] = arg['argument']\n",
    "                        if len(sop.keys()) == 3:\n",
    "                            tmp['results'].append(sop.copy())  \n",
    "\n",
    "                    if arg['role'] == '被参股方|公司':\n",
    "                        sop['tail'] = arg['argument']\n",
    "                        if len(sop.keys()) == 3:\n",
    "                            tmp['results'].append(sop.copy())  \n",
    "                              \n",
    "            ret.append(tmp)\n",
    "            '''\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "856\n"
     ]
    }
   ],
   "source": [
    "b = clean_parse_events(event)\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '本次交易中深天马拟通过向特定对象非公开发行股份购买上海天马70%股权、成都天马40%股权、武汉天马90%股权、上海光电子100%股权、深圳光电子100%股权，并募集配套资金。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '中深天马',\n",
       "      'role': '买方|公司',\n",
       "      'argument_start_index': 4},\n",
       "     {'argument': '上海天马', 'role': '卖方|公司', 'argument_start_index': 25},\n",
       "     {'argument': '70%', 'role': '股权类数据|数值', 'argument_start_index': 29},\n",
       "     {'argument': '股权', 'role': '股权类产品|产品', 'argument_start_index': 32},\n",
       "     {'argument': '成都天马', 'role': '卖方|公司', 'argument_start_index': 35},\n",
       "     {'argument': '40%', 'role': '股权类数据|数值', 'argument_start_index': 39},\n",
       "     {'argument': '武汉天马', 'role': '卖方|公司', 'argument_start_index': 45},\n",
       "     {'argument': '上海光电子', 'role': '卖方|公司', 'argument_start_index': 55},\n",
       "     {'argument': '深圳光电子', 'role': '卖方|公司', 'argument_start_index': 67}]}]},\n",
       " {'text': '根据初步预估，标的资产上海天马70%股权、成都天马40%股权、武汉天马90%股权、上海光电子100%股权、深圳光电子100%股权的预估值分别为122,875.99万元、58,058.23万元、163,594.20万元、167,111.90万元、29,962.13万元，总计541,602.45万元，深天马预计发行总计42,679.47万股股份购买上述股权。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '上海天马',\n",
       "      'role': '卖方|公司',\n",
       "      'argument_start_index': 11},\n",
       "     {'argument': '成都天马', 'role': '卖方|公司', 'argument_start_index': 21},\n",
       "     {'argument': '40%', 'role': '股权类数据|数值', 'argument_start_index': 25},\n",
       "     {'argument': '武汉天马', 'role': '卖方|公司', 'argument_start_index': 31},\n",
       "     {'argument': '90%', 'role': '股权类数据|数值', 'argument_start_index': 35},\n",
       "     {'argument': '上海光电子', 'role': '卖方|公司', 'argument_start_index': 41},\n",
       "     {'argument': '深圳光电子', 'role': '卖方|公司', 'argument_start_index': 53},\n",
       "     {'argument': '深天马', 'role': '买方|公司', 'argument_start_index': 149}]}]},\n",
       " {'text': '本公司认为收购Neta股权有利于推动本公司在土耳其的业务拓展。',\n",
       "  'pre_events': [{'trigger': '收购',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '本公司',\n",
       "      'role': '买方|公司',\n",
       "      'argument_start_index': 0},\n",
       "     {'argument': 'Neta', 'role': '卖方|公司', 'argument_start_index': 7},\n",
       "     {'argument': '股权', 'role': '股权类产品|产品', 'argument_start_index': 11}]}]},\n",
       " {'text': '买卖协议（该协议已于2011年11月1日晚正式签署）（1）根据买卖协议，冠捷科技向飞利浦购买合营公司70%的股份。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '冠捷科技',\n",
       "      'role': '买方|公司',\n",
       "      'argument_start_index': 36},\n",
       "     {'argument': '飞利浦', 'role': '买方|公司', 'argument_start_index': 41},\n",
       "     {'argument': '合营公司', 'role': '卖方|公司', 'argument_start_index': 46},\n",
       "     {'argument': '70%', 'role': '股权类数据|数值', 'argument_start_index': 50}]}]},\n",
       " {'text': '于收购完成时，各方约定对桑菲通信重新审计，如桑菲通信经审计的净资产低于（不含）人民币1,500万元，则卖方将以现金或令买方满意的其他方式向桑菲通信支付成交审计净资产与人民币1,500万元之间的差额；如桑菲通信经审计的净资产高于（不含）人民币7,500万元，则买方将向卖方支付成交审计净资产与人民币7,500万元之间的差额，该差额上限为人民币2,000万元。',\n",
       "  'pre_events': [{'trigger': '收购',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '桑菲通信',\n",
       "      'role': '卖方|公司',\n",
       "      'argument_start_index': 12},\n",
       "     {'argument': '桑菲通信', 'role': '买方|公司', 'argument_start_index': 22}]}]},\n",
       " {'text': '3、发行股份购买资产本次交易长城电脑拟非公开发行股份购买中原电子35.02%股权、圣非凡100%股权和中国电子因国有资本金确权对长城电脑形成的1.65亿债权。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '长城电脑',\n",
       "      'role': '买方|公司',\n",
       "      'argument_start_index': 14},\n",
       "     {'argument': '中原电子', 'role': '卖方|公司', 'argument_start_index': 28},\n",
       "     {'argument': '35.02%', 'role': '股权类数据|数值', 'argument_start_index': 32},\n",
       "     {'argument': '股权', 'role': '股权类产品|产品', 'argument_start_index': 38},\n",
       "     {'argument': '圣非凡', 'role': '卖方|公司', 'argument_start_index': 41}]}]},\n",
       " {'text': '2009年5月18日,深圳赛格股份有限公司在上述减持过程中,由于工作人员的操作失误,误将“卖出”指令操作成“买入”指令,并误买入本公司股票“48,880股”,买入价格为3.89元/股。',\n",
       "  'pre_events': [{'trigger': '买入',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '2009年5月18日',\n",
       "      'role': 'DATE',\n",
       "      'argument_start_index': 0},\n",
       "     {'argument': '深圳赛格股份有限公司', 'role': '买方|公司', 'argument_start_index': 11},\n",
       "     {'argument': '本公司', 'role': '卖方|公司', 'argument_start_index': 64},\n",
       "     {'argument': '股票', 'role': '股权类产品|产品', 'argument_start_index': 67}]}]},\n",
       " {'text': '此外,宏盛股份拟以资产置换及发行股份并支付现金的方式向其他三名自然人购买文旅科技40%股权。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '宏盛股份',\n",
       "      'role': '买方|公司',\n",
       "      'argument_start_index': 3},\n",
       "     {'argument': '文旅科技', 'role': '卖方|公司', 'argument_start_index': 36},\n",
       "     {'argument': '40%', 'role': '股权类数据|数值', 'argument_start_index': 40},\n",
       "     {'argument': '股权', 'role': '股权类产品|产品', 'argument_start_index': 43}]}]},\n",
       " {'text': '本公司与海王英特龙、江苏海王生物于2015年12月30日签署《泰州海王纳米生物医学科技有限公司股权转让及在申请中相关专利权和商标转让协议》，约定公司以人民币100万元的价格收购海王纳米公司100%股权和海王英特龙、江苏海王生物拥有的与海王纳米相关的【14项】正在申请中的专利权及【2项】正在申请中的商标。',\n",
       "  'pre_events': [{'trigger': '收购',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '公司',\n",
       "      'role': '买方|公司',\n",
       "      'argument_start_index': 72},\n",
       "     {'argument': '海王纳米公司', 'role': '卖方|公司', 'argument_start_index': 88},\n",
       "     {'argument': '100%', 'role': '股权类数据|数值', 'argument_start_index': 94},\n",
       "     {'argument': '海王英特龙', 'role': '卖方|公司', 'argument_start_index': 101}]}]},\n",
       " {'text': '一、交易概述2019年5月10日，上海临港控股股份有限公司（以下简称“上海临港”）披露了《上海临港控股股份有限公司发行股份及支付现金购买资产并募集配套资金暨关联交易报告书（修订稿）》（以下简称“《报告书》”）。',\n",
       "  'pre_events': [{'trigger': '购买',\n",
       "    'event_type': '购买事件',\n",
       "    'arguments': [{'argument': '2019年5月10日',\n",
       "      'role': 'DATE',\n",
       "      'argument_start_index': 6},\n",
       "     {'argument': '上海临港控股股份有限公司', 'role': '买方|公司', 'argument_start_index': 17},\n",
       "     {'argument': '上海临港控股股份有限公司',\n",
       "      'role': '卖方|公司',\n",
       "      'argument_start_index': 45}]}]}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '交易概述。', 'results': []},\n",
       " {'text': '没有单位。', 'results': []},\n",
       " {'text': '转让方有权选择以现金对价人民币11,449,117,658元(“现金对价”)或以中国平安新发行的299,088,758股H股股份(“对价股份”)收取交易对价。',\n",
       "  'results': []},\n",
       " {'text': '2012-05-15：1港币=0.813人民币元。', 'results': []},\n",
       " {'text': '本次询价转让存托凭证的数量为17,600,000份，占九号公司存托凭证总数量的比例为2.50%，转让原因为自身资金需求。',\n",
       "  'results': []},\n",
       " {'text': '转让存托凭证持有人名称转让存托凭证数量（份）占公司存托凭证总数量比例占所持存托凭证数量的比例转让原因SequoiaCapitalChinaGFHoldcoIII-A,Ltd.6,300,0000.89%5.92%自身资金需求PeopleBetterLimited4,085,0000.58%5.91%自身资金需求ShunweiTMTIIILimited4,085,0000.58%5.91%自身资金需求WestSummitGlobalTechnologyFund,L.P.300,0000.04%0.85%自身资金需求WtmtechLimited1,450,0000.21%4.66%自身资金需求IntelCapitalCorporation600,0000.09%2.85%自身资金需求ZhaoduanLimited10,0000.00%0.07%自身资金需求CliffInvestmentPte.Ltd.730,0000.10%5.89%自身资金需求WltechLimited10,0000.00%0.16%自身资金需求WestOriginFTLP30,0000.00%0.73%自身资金需求。',\n",
       "  'results': []},\n",
       " {'text': '2009年6月12日,信息披露义务人与中国平安签署了《股份购买协议》,协议主要内容如下:转让方将向受让方转让其持有的深发展520,414,439股股份,占深发展总股本的16.76%。',\n",
       "  'results': []},\n",
       " {'text': '深圳发展银行股份有限公司拟向中国平安保险（集团）股份有限公司（“中国平安”）发行股份（“本次发行”），中国平安拟以其持有的平安银行股份有限公司（“平安银行”）约90.75%的股份以及部分现金认购公司本次发行的股份。',\n",
       "  'results': []},\n",
       " {'text': '公司之全资子公司万科置业（香港）有限公司（简称“万科置业”）于2012年5月13日与永泰地产有限公司（简称“永泰地产”，香港联合交易所股份代码0369）达成协议，在南联地产控股有限公司（简称“南联地产”，香港联合交易所股份代码1036）进行公司重组后，万科置业将通过其全资子公司WklandInvestmentsCompanyLimited以约港币10.79亿元向永泰地产收购重组后的南联地产191,935,845股股份，占重组后的南联地产已发行股份总数的约73.91%。',\n",
       "  'results': [{'head': '公司', 'relation': '子公司', 'tail': '万科置业（香港）有限公司'}]},\n",
       " {'text': '2012-07-18：1港币=0.8218人民币元2012年7月16日，南联地产完成公司重组；前述股份收购已经完成，WklandInvestmentsCompanyLimited已经持有重组后的南联地产205,835,845股股份，占重组后的南联地产已发行股份总数的约79.26%。',\n",
       "  'results': []},\n",
       " {'text': '武汉中百集团股份有限公司同时承担金田集团及其下属企业欠武汉金田超市有限公司责任公司的债务净额560.67万元。',\n",
       "  'results': []},\n",
       " {'text': '武汉金田连锁商场有限责任公司总资产3，743万元，总负债3，964万元，净资产为-221万元，主营收入9，486万元，净利润为-54万元。',\n",
       "  'results': []},\n",
       " {'text': '武汉金田超市有限责任公司总资产1，024万元，总负债563万元，净资产为461万元，主营收入948万元，净利润为-1万元。',\n",
       "  'results': []},\n",
       " {'text': '其中4,198,834股已于2007年8月20日取得上市流通权。', 'results': []},\n",
       " {'text': '本次交易对手方为深圳市京王实业有限公司，交易价格以经具有证券从业资格的第三方评估机构出具的广州火舞截止2019年6月30日股东全部权益价值为依据，双方协商确定股权转让价格为5,200万元人民币整。',\n",
       "  'results': []},\n",
       " {'text': '本次交易不构成关联交易，亦不构成《上市公司重大资产重组管理办法》规定的重大资产重组。', 'results': []},\n",
       " {'text': '1、本司与中国银行在2007年4月28日达成如下协议:本司须在2007年8月30日前分5批偿还全部逾期贷款本金4900万元及利息和费用,中国银行同意在收到相应批次的还款后分批解除对应质押物,如本司在2007年8月30日前偿还全部逾期贷款本金4900万元及利息和相关费用,则中国银行同意免除上述债务的复利、罚息。',\n",
       "  'results': []},\n",
       " {'text': '概述：经本公司与武汉中百集团股份有限公司协商，同意本公司控股企业--深圳市金田商业网络发展有限公司与深圳市金田投资有限公司将所持有的武汉金田连锁商场有限责任公司、武汉金田超市有限责任公司的股权全部转让给武汉中百集团股份有限公司、武汉中百仓储连锁超市有限公司，转让金额合计430万元。',\n",
       "  'results': []},\n",
       " {'text': '公司于今日下午收到第二大股东即有限售条件流通股股东招商局地产控股股份有限公司通知,2007年12月28日出售其持有的本公司股权4,198,834股,占公司总股本4.999%。',\n",
       "  'results': []},\n",
       " {'text': '招商局地产控股股份有限公司为公司第二大股东,持有公司股权4,688,658股,占公司总股本5.58%。',\n",
       "  'results': []}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_relations(relations):\n",
    "    ret = []\n",
    "    for item in relations:\n",
    "        results = item['results']\n",
    "        if results:\n",
    "            add = True\n",
    "            #for rel in results:\n",
    "            #    if rel['head'] == '公司':\n",
    "            #        add = False\n",
    "            #        break\n",
    "            if add:\n",
    "                ret.append(item)\n",
    "    return ret\n",
    "a = clean_relations(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '基于神州高铁整线智能运营优势以及在天津市轨道交通的深耕布局,经与中国交建等方面洽商一致,2020年7月15日神州高铁及子公司神州高铁轨道交通运营管理有限公司(以下简称“神铁运营”,神州高铁与神铁运营合称“神州高铁方”)与中国交建签署了《天津地铁2、3号线存量PPP项目股权转让框架协议》,中国交建同意按照天津市政府转让的相关条件,将其持有的2号线和3号线项目公司部分股权转让给神州高铁方,神州高铁方同意按照相关条件受让前述股权。',\n",
       "  'results': [{'head': '神州高铁',\n",
       "    'relation': '子公司',\n",
       "    'tail': '神州高铁轨道交通运营管理有限公司'}]},\n",
       " {'text': '为解决宝安鸿基地产集团股份有限公司（以下简称“宝安地产”）与本公司在惠州地区存在的同业竞争，宝安地产拟以人民币17,000万元受让本公司之全资子公司惠州市宝安房地产开发有限公司（以下简称“惠州地产公司”）100%股权。',\n",
       "  'results': [{'head': '本公司', 'relation': '子公司', 'tail': '惠州市宝安房地产开发有限公司'},\n",
       "   {'head': '本公司', 'relation': '子公司', 'tail': '惠州市宝安房地产开发有限公司'}]},\n",
       " {'text': '惠州市宝安房地产开发有限公司股东结构：本公司持股99.8％，本公司之全资子公司中国宝安集团投资有限公司（以下简称“中宝投资”）持股0.2％。',\n",
       "  'results': [{'head': '本公司', 'relation': '子公司', 'tail': '中国宝安集团投资有限公司'},\n",
       "   {'head': '本公司', 'relation': '子公司', 'tail': '中国宝安集团投资有限公司'}]},\n",
       " {'text': '本公司于2015年12月14日召开第十二届董事局第三十七次会议,审议通过了《关于全资子公司拟有条件全面要约收购国际精密集团有限公司股权的议案》,本公司全资子公司宝安科技有限公司拟以每股1.5港元的价格有条件全面要约收购国际精密集团有限公司(以下简称“目标公司”或“国际精密“)股权,并拟注销目标公司尚未行使的全部期权,注销价格根据要约价与期权行使价的差额来确定。',\n",
       "  'results': [{'head': '本公司', 'relation': '子公司', 'tail': '宝安科技有限公司'}]},\n",
       " {'text': '截至2017年3月21日,本公司全资子公司宝安科技有限公司(以下简称“宝安科技”)持有国际精密集团有限公司(以下简称“国际精密”或“目标公司”)37,364万股,占其总股本35.51%,为其第一大股东。',\n",
       "  'results': [{'head': '本公司', 'relation': '子公司', 'tail': '宝安科技有限公司'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN ORIGINAL DATA\n",
    "\n",
    "import json\n",
    "relation = []\n",
    "event = []\n",
    "with open('./JD_example.json', 'r', encoding='utf-8') as json_file:\n",
    "    f = json_file.readlines()\n",
    "    for line in f:\n",
    "        json_line = json.loads(line.strip())\n",
    "        relation += json_line['result']['data']['normal']\n",
    "        event += json_line['result']['data']['cangu']\n",
    "def clean_relations(relations):\n",
    "    ret = []\n",
    "    for item in relations:\n",
    "        results = item['results']\n",
    "        if results:\n",
    "            add = True\n",
    "            for rel in results:\n",
    "                if rel['head'] == '公司':\n",
    "                    add = False\n",
    "                    break\n",
    "            if add:\n",
    "                ret.append(item)\n",
    "    return ret\n",
    "a = clean_relations(relation)\n",
    "\n",
    "def clean_parse_events(events):\n",
    "    ret = []\n",
    "    tri_dic = {}\n",
    "    for item in events:\n",
    "        es = item['pre_events']\n",
    "        for e in es:\n",
    "            tri_dic[e['trigger']] = tri_dic[e['trigger']] + 1 if e['trigger'] in tri_dic else 1\n",
    "    white_triggers = [key  for key in tri_dic if tri_dic[key] >= 5]\n",
    "    \n",
    "    for item in events:\n",
    "        es = item['pre_events']\n",
    "        add = True\n",
    "        for e in es:\n",
    "            if e['trigger'] not in white_triggers or len(e['arguments']) < 2 or e['event_type'] != '参股事件':\n",
    "                add = False\n",
    "                break\n",
    "        if add:\n",
    "            #ret.append(item)\n",
    "            tmp = {}\n",
    "            tmp['text'] = item['text']\n",
    "            tmp['results'] = []\n",
    "            for e in es:\n",
    "                sop = {}\n",
    "                sop['relation'] = '参股'\n",
    "                for arg in e['arguments']:\n",
    "                    if arg['role'] == '参股方|公司':\n",
    "                        sop['head'] = arg['argument']\n",
    "                        if len(sop.keys()) == 3:\n",
    "                            tmp['results'].append(sop.copy())  \n",
    "\n",
    "                    if arg['role'] == '被参股方|公司':\n",
    "                        sop['tail'] = arg['argument']\n",
    "                        if len(sop.keys()) == 3:\n",
    "                            tmp['results'].append(sop.copy())  \n",
    "                              \n",
    "            ret.append(tmp)\n",
    "    return ret\n",
    "b = clean_parse_events(event)\n",
    "c = clean_relations(b)\n",
    "data = a + c\n",
    "import random\n",
    "train = []\n",
    "test = []\n",
    "dev = []\n",
    "for tmp in data:\n",
    "    r = random.random()\n",
    "    if r < 0.2:\n",
    "        test.append(tmp)\n",
    "    elif r < 0.92:\n",
    "        train.append(tmp)\n",
    "    else:\n",
    "        dev.append(tmp)\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)\n",
    "random.shuffle(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "dev = []\n",
    "for tmp in a:\n",
    "    r = random.random()\n",
    "    if r < 0.2:\n",
    "        test.append(tmp)\n",
    "    elif r < 0.92:\n",
    "        train.append(tmp)\n",
    "    else:\n",
    "        dev.append(tmp)\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)\n",
    "random.shuffle(dev)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
